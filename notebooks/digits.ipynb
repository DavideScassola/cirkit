{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1e6d6b9",
   "metadata": {},
   "source": [
    "# Train and evaluate a PC"
   ]
  },
  {
   "cell_type": "code",
   "id": "d6debe19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T09:32:19.854497Z",
     "start_time": "2024-07-29T09:32:19.591738Z"
    }
   },
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "c4608165",
   "metadata": {},
   "source": [
    "Set the random seeds."
   ]
  },
  {
   "cell_type": "code",
   "id": "d66933b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T09:32:19.858106Z",
     "start_time": "2024-07-29T09:32:19.855615Z"
    }
   },
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "45c005fb",
   "metadata": {},
   "source": [
    "## Load MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a02baea",
   "metadata": {},
   "source": [
    "Load the training and test splits of MNIST, and preprocess them by flattening the tensor images."
   ]
  },
  {
   "cell_type": "code",
   "id": "f3a04559",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T09:32:21.317338Z",
     "start_time": "2024-07-29T09:32:19.858949Z"
    }
   },
   "source": [
    "from torchvision import transforms, datasets\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: (255 * x.view(-1)).long())\n",
    "])\n",
    "data_train = datasets.MNIST('datasets', train=True, download=True, transform=transform)\n",
    "data_test = datasets.MNIST('datasets', train=False, download=True, transform=transform)\n",
    "num_variables = data_train[0][0].shape[0]\n",
    "height, width = 28, 28\n",
    "print(f\"Number of variables: {num_variables}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of variables: 784\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "6ad24d46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T09:32:21.459110Z",
     "start_time": "2024-07-29T09:32:21.318584Z"
    }
   },
   "source": [
    "plt.matshow(data_train[0][0].reshape(28, 28), cmap='gray')\n",
    "plt.title(f\"Class: {data_train[0][1]}\")\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 345.6x345.6 with 1 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "965d0122",
   "metadata": {},
   "source": [
    "## Instantiating a Circuit structure Template: the Region Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d471b6e",
   "metadata": {},
   "source": [
    "Initialize a _Quad Graph_ region graph."
   ]
  },
  {
   "cell_type": "code",
   "id": "51a7b261",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T09:32:21.616303Z",
     "start_time": "2024-07-29T09:32:21.461085Z"
    }
   },
   "source": [
    "from cirkit.templates.region_graph import QuadTree\n",
    "region_graph = QuadTree(shape=(height, height))"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "0dc35ef6",
   "metadata": {},
   "source": [
    "Others available region graphs are the _Random Binary Tree_ and the _Poon Domingos_, whose imports are showed below."
   ]
  },
  {
   "cell_type": "code",
   "id": "ec3a1ea4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T09:32:21.619606Z",
     "start_time": "2024-07-29T09:32:21.617392Z"
    }
   },
   "source": [
    "from cirkit.templates.region_graph import RandomBinaryTree, PoonDomingos"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "66900897-5d65-4136-8399-f997c3665a38",
   "metadata": {},
   "source": [
    "## Constructing the Symbolic Circuit Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6468f6-a1e5-46f8-92d4-d1eb6fa5ba19",
   "metadata": {},
   "source": [
    "From the region graph definition above, we now construct the symbolic circuit representation. Note that this circuit representation is _not_ executable, i.e., you cannot do learn it or do inference with it. It will be compiled later, by choosing a backend such as torch.\n",
    "\n",
    "To do so, we first define the factories that will be used to construct symbolic layers. Note that we choose the parameterization at the symbolic level. That is, we guarantee non-negative parameters by passing them through an exponential function. Moreover, we can choose how to parameterize the categorical distributions used to model the distribution of pixel values in the 0-255 range. In this case, we use a log softmax function. We choose to initialize the weights of the circuit by sampling from a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "id": "ac0a1895-999f-47af-8c6f-57242726540a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T09:32:21.631692Z",
     "start_time": "2024-07-29T09:32:21.620606Z"
    }
   },
   "source": [
    "from cirkit.utils.scope import Scope\n",
    "from cirkit.symbolic.parameters import LogSoftmaxParameter, ExpParameter, Parameter, SoftmaxParameter\n",
    "from cirkit.symbolic.layers import CategoricalLayer, DenseLayer, HadamardLayer, MixingLayer\n",
    "from cirkit.symbolic.initializers import NormalInitializer"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "c96b9dfc-83a6-43ba-b20d-48d6dd79e663",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T09:32:21.647167Z",
     "start_time": "2024-07-29T09:32:21.632582Z"
    }
   },
   "source": [
    "def categorical_layer_factory(\n",
    "    scope: Scope,\n",
    "    num_units: int,\n",
    "    num_channels: int\n",
    ") -> CategoricalLayer:\n",
    "    return CategoricalLayer(\n",
    "        scope, num_units, num_channels, num_categories=256,\n",
    "        parameterization=lambda p: Parameter.from_unary(p, LogSoftmaxParameter(p.shape)),\n",
    "        initializer=NormalInitializer(0.0, 1e-2)\n",
    "    )\n",
    "\n",
    "def hadamard_layer_factory(\n",
    "    scope: Scope, num_input_units: int, arity: int\n",
    ") -> HadamardLayer:\n",
    "    return HadamardLayer(scope, num_input_units, arity)\n",
    "\n",
    "def dense_layer_factory(\n",
    "    scope: Scope,\n",
    "    num_input_units: int,\n",
    "    num_output_units: int\n",
    ") -> DenseLayer:\n",
    "    return DenseLayer(\n",
    "        scope, num_input_units, num_output_units,\n",
    "        parameterization=lambda p: Parameter.from_unary(p, SoftmaxParameter(p.shape)),\n",
    "        initializer=NormalInitializer(0.0, 1e-1)\n",
    "    )\n",
    "\n",
    "\n",
    "def mixing_layer_factory(\n",
    "    scope: Scope, num_units: int, arity: int\n",
    ") -> MixingLayer:\n",
    "    return MixingLayer(\n",
    "        scope, num_units, arity,\n",
    "        parameterization=lambda p: Parameter.from_unary(p, SoftmaxParameter(p.shape)),\n",
    "        initializer=NormalInitializer(0.0, 1e-1)\n",
    "    )"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "9707de19-d6c7-4646-8266-2e20dcefa22e",
   "metadata": {},
   "source": [
    "Then, we call a function to construct the symbolic circuit from region graph, by specifying the number of units and the factories to build layers."
   ]
  },
  {
   "cell_type": "code",
   "id": "97be2b8f-0012-46ed-9f03-26a7a4729b61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T09:32:21.662995Z",
     "start_time": "2024-07-29T09:32:21.648234Z"
    }
   },
   "source": [
    "from cirkit.symbolic.circuit import Circuit"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "52c88f38-1552-4d13-b62d-931493c07c69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T09:32:21.713056Z",
     "start_time": "2024-07-29T09:32:21.663725Z"
    }
   },
   "source": [
    "symbolic_circuit = Circuit.from_region_graph(\n",
    "    region_graph,\n",
    "    num_input_units=8,\n",
    "    num_sum_units=8,\n",
    "    input_factory=categorical_layer_factory,\n",
    "    sum_factory=dense_layer_factory,\n",
    "    prod_factory=hadamard_layer_factory,\n",
    "    mixing_factory=mixing_layer_factory\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "aa8c6e7c-ad9f-4dd2-ab76-602e191d197b",
   "metadata": {},
   "source": [
    "We can retrieve some information about the circuit and its structural properties as follows."
   ]
  },
  {
   "cell_type": "code",
   "id": "23570bfd-a64e-4e19-ba4c-30e489e9d08d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T09:32:21.722485Z",
     "start_time": "2024-07-29T09:32:21.714051Z"
    }
   },
   "source": [
    "print(f'Smooth: {symbolic_circuit.is_smooth}')\n",
    "print(f'Decomposable: {symbolic_circuit.is_decomposable}')\n",
    "print(f'Number of variables: {symbolic_circuit.num_variables}')\n",
    "print(f'Number of channels per variable: {symbolic_circuit.num_channels}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smooth: True\n",
      "Decomposable: True\n",
      "Number of variables: 784\n",
      "Number of channels per variable: 1\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "67398c38",
   "metadata": {},
   "source": [
    "## Compiling the Symbolic Circuit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba547d8",
   "metadata": {},
   "source": [
    "We are ready to compile the symbolic circuit constructed above into another one that we can learn and/or do inference. To do so, we have to choose a compilation backend. In this case, we choose torch as a backend."
   ]
  },
  {
   "cell_type": "code",
   "id": "a9ea4a4a-649d-462f-bcfd-20a12bd8a052",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T09:32:21.744107Z",
     "start_time": "2024-07-29T09:32:21.723468Z"
    }
   },
   "source": [
    "import torch\n",
    "device = torch.device('cuda')  # The device to use\n",
    "torch.manual_seed(42)\n",
    "if 'cuda' in device.type:\n",
    "    torch.cuda.manual_seed(42)"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "b7f7a3f9-1c64-4117-81f0-8766ccbd3179",
   "metadata": {},
   "source": [
    "We first need to instantiate a circuit pipeline context and specify the backend to be used, as well as optional compilation flags, e.g., whether to fold the circuit or which inference semiring to use. Finally, we use the pipeline context to compile the symbolic circuit."
   ]
  },
  {
   "cell_type": "code",
   "id": "af58c11e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T09:32:21.775874Z",
     "start_time": "2024-07-29T09:32:21.747454Z"
    }
   },
   "source": [
    "from cirkit.pipeline import PipelineContext"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "c0a1892e-4a65-4759-bb3a-ccbe6f5e515c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T09:32:22.503274Z",
     "start_time": "2024-07-29T09:32:21.777475Z"
    }
   },
   "source": [
    "%%time\n",
    "ctx = PipelineContext(\n",
    "    backend='torch',   # Choose the torch compilation backend\n",
    "    fold=True,         # Fold the circuit, this is a backend-specific compilation flag\n",
    "    semiring='lse-sum' # Use the (R, +, *) semiring, where + is the log-sum-exp and * is the sum\n",
    ")\n",
    "circuit = ctx.compile(symbolic_circuit)\n",
    "\n",
    "# Alternatively, one can use the Python _with_ statement to compile circuits inside of it.\n",
    "#\n",
    "# from cirkit.pipeline import compile\n",
    "# with PipelineContext(backend='torch', fold=True, semiring='lse-sum') as ctx:\n",
    "#    circuit = compile(symbolic_circuit)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 708 ms, sys: 12.8 ms, total: 721 ms\n",
      "Wall time: 722 ms\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "bdd14baf-a29e-4773-84a7-417d8747f678",
   "metadata": {},
   "source": [
    "Note that the compilation step, comprising the folding optimization, required less than 1 second for a circuit with almost 5000 layers."
   ]
  },
  {
   "cell_type": "code",
   "id": "36f0d55e-05c3-42ac-a63c-326f8446f90d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T09:32:22.507535Z",
     "start_time": "2024-07-29T09:32:22.504167Z"
    }
   },
   "source": [
    "print(len(list(symbolic_circuit.layers)))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4947\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "id": "f1ce78e8-79fc-4630-8cea-ce6e0df4429b",
   "metadata": {},
   "source": [
    "We observe how the tensorized circuit has much fewer layers, as the great majority has been folded."
   ]
  },
  {
   "cell_type": "code",
   "id": "cc7965af-05d3-472f-84cb-7c3d80da52fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T09:32:22.524964Z",
     "start_time": "2024-07-29T09:32:22.508185Z"
    }
   },
   "source": [
    "print(circuit)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TorchCircuit(\n",
      "  (_nodes): ModuleList(\n",
      "    (0): TorchCategoricalLayer(\n",
      "      (logits): TorchParameter(\n",
      "        (_nodes): ModuleList(\n",
      "          (0): TorchTensorParameter()\n",
      "          (1): TorchLogSoftmaxParameter()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): TorchDenseLayer(\n",
      "      (weight): TorchParameter(\n",
      "        (_nodes): ModuleList(\n",
      "          (0): TorchTensorParameter()\n",
      "          (1): TorchSoftmaxParameter()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): TorchHadamardLayer()\n",
      "    (3): TorchDenseLayer(\n",
      "      (weight): TorchParameter(\n",
      "        (_nodes): ModuleList(\n",
      "          (0): TorchTensorParameter()\n",
      "          (1): TorchSoftmaxParameter()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): TorchHadamardLayer()\n",
      "    (5): TorchDenseLayer(\n",
      "      (weight): TorchParameter(\n",
      "        (_nodes): ModuleList(\n",
      "          (0): TorchTensorParameter()\n",
      "          (1): TorchSoftmaxParameter()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (6): TorchMixingLayer(\n",
      "      (weight): TorchParameter(\n",
      "        (_nodes): ModuleList(\n",
      "          (0): TorchTensorParameter()\n",
      "          (1): TorchSoftmaxParameter()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (7): TorchHadamardLayer()\n",
      "    (8): TorchDenseLayer(\n",
      "      (weight): TorchParameter(\n",
      "        (_nodes): ModuleList(\n",
      "          (0): TorchTensorParameter()\n",
      "          (1): TorchSoftmaxParameter()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (9): TorchHadamardLayer()\n",
      "    (10): TorchDenseLayer(\n",
      "      (weight): TorchParameter(\n",
      "        (_nodes): ModuleList(\n",
      "          (0): TorchTensorParameter()\n",
      "          (1): TorchSoftmaxParameter()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (11): TorchMixingLayer(\n",
      "      (weight): TorchParameter(\n",
      "        (_nodes): ModuleList(\n",
      "          (0): TorchTensorParameter()\n",
      "          (1): TorchSoftmaxParameter()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (12): TorchHadamardLayer()\n",
      "    (13): TorchDenseLayer(\n",
      "      (weight): TorchParameter(\n",
      "        (_nodes): ModuleList(\n",
      "          (0): TorchTensorParameter()\n",
      "          (1): TorchSoftmaxParameter()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (14): TorchHadamardLayer()\n",
      "    (15): TorchDenseLayer(\n",
      "      (weight): TorchParameter(\n",
      "        (_nodes): ModuleList(\n",
      "          (0): TorchTensorParameter()\n",
      "          (1): TorchSoftmaxParameter()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (16): TorchMixingLayer(\n",
      "      (weight): TorchParameter(\n",
      "        (_nodes): ModuleList(\n",
      "          (0): TorchTensorParameter()\n",
      "          (1): TorchSoftmaxParameter()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (17): TorchHadamardLayer()\n",
      "    (18): TorchDenseLayer(\n",
      "      (weight): TorchParameter(\n",
      "        (_nodes): ModuleList(\n",
      "          (0): TorchTensorParameter()\n",
      "          (1): TorchSoftmaxParameter()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (19): TorchHadamardLayer()\n",
      "    (20): TorchDenseLayer(\n",
      "      (weight): TorchParameter(\n",
      "        (_nodes): ModuleList(\n",
      "          (0): TorchTensorParameter()\n",
      "          (1): TorchSoftmaxParameter()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (21): TorchMixingLayer(\n",
      "      (weight): TorchParameter(\n",
      "        (_nodes): ModuleList(\n",
      "          (0): TorchTensorParameter()\n",
      "          (1): TorchSoftmaxParameter()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (22): TorchHadamardLayer()\n",
      "    (23): TorchDenseLayer(\n",
      "      (weight): TorchParameter(\n",
      "        (_nodes): ModuleList(\n",
      "          (0): TorchTensorParameter()\n",
      "          (1): TorchSoftmaxParameter()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (24): TorchHadamardLayer()\n",
      "    (25): TorchDenseLayer(\n",
      "      (weight): TorchParameter(\n",
      "        (_nodes): ModuleList(\n",
      "          (0): TorchTensorParameter()\n",
      "          (1): TorchSoftmaxParameter()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (26): TorchMixingLayer(\n",
      "      (weight): TorchParameter(\n",
      "        (_nodes): ModuleList(\n",
      "          (0): TorchTensorParameter()\n",
      "          (1): TorchSoftmaxParameter()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "id": "beee1f04",
   "metadata": {},
   "source": [
    "## Training and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bf4858",
   "metadata": {},
   "source": [
    "We are now ready to learn the parameters and do inference First, we wrap our data into PyTorch data loaders by specifying the batch size. Then, we initialize any PyTorch optimizer, e.g. SGD with momentum in this case."
   ]
  },
  {
   "cell_type": "code",
   "id": "02854883",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T09:32:22.534293Z",
     "start_time": "2024-07-29T09:32:22.525742Z"
    }
   },
   "source": [
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "train_dataloader = DataLoader(data_train, shuffle=True, batch_size=256, drop_last=True, num_workers=4)\n",
    "test_dataloader = DataLoader(data_test, shuffle=False, batch_size=256, num_workers=4)\n",
    "optimizer = optim.SGD(circuit.parameters(), lr=0.1, momentum=0.95)"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "id": "ab362742-03af-4839-a302-44c8492a370e",
   "metadata": {},
   "source": [
    "### Compiling the Circuit computing the Partition Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbac573d",
   "metadata": {},
   "source": [
    "Here, we choose to optimize the parameters by minimizing the negative log-likelihood. However, since the circuit is not already normalized (as we parameterized the sums using an exponential), we need to instantiate a circuit computing the partition function explicitly. That is, we integrate the circuit within the pipeline context as follows."
   ]
  },
  {
   "cell_type": "code",
   "id": "de1ae885-d02a-4c94-829e-dc491a8c4a8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T09:32:23.517288Z",
     "start_time": "2024-07-29T09:32:22.535038Z"
    }
   },
   "source": [
    "pf_circuit = ctx.integrate(circuit)\n",
    "\n",
    "# Alternatively, one can use the _with_ statement.\n",
    "#\n",
    "# from cirkit.pipeline import integrate\n",
    "# with ctx:\n",
    "#     pf_circuit = integrate(tensorized_circuit)\n",
    "\n",
    "# Another way to perform the integration is by using the _symbolic functional_ APIs.\n",
    "# This gives us additional flexibility by operating over circuits _before compiling them_.\n",
    "#\n",
    "# import cirkit.symbolic.functional as SF\n",
    "# with ctx:\n",
    "#     pf_symbolic_circuit = SF.integrate(symbolic_circuit)\n",
    "#     pf_circuit = compile(pf_symbolic_circuit)\n",
    "\n",
    "# The type of the circuit obtained by integration of all variables is a 'constant' circuit,\n",
    "# i.e., it does not take inputs.\n",
    "print(type(pf_circuit))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'cirkit.backend.torch.models.TorchConstantCircuit'>\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "id": "3e05e268-4ab0-4c65-94b6-f624329bee55",
   "metadata": {},
   "source": [
    "Note that the context will take care of the parameters being shared between the compiled circuit and its other version, which computes the partition function. Finally, we learn the parameters by minimizing the negative log-likelihood, similarly as any other model in torch."
   ]
  },
  {
   "cell_type": "code",
   "id": "8eb6683d-f7c0-4b70-afd1-912a90861c9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T09:32:23.596259Z",
     "start_time": "2024-07-29T09:32:23.518111Z"
    }
   },
   "source": [
    "# Move circuits to device\n",
    "circuit = circuit.to(device)\n",
    "pf_circuit = pf_circuit.to(device)"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "2f28e9c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T09:32:56.230359Z",
     "start_time": "2024-07-29T09:32:23.597283Z"
    }
   },
   "source": [
    "num_epochs = 25\n",
    "step_idx = 0\n",
    "running_loss = 0.0\n",
    "for epoch_idx in range(num_epochs):\n",
    "    for i, (batch, _) in enumerate(train_dataloader):\n",
    "        batch = batch.to(device).unsqueeze(dim=1)   # Add a channel dimension\n",
    "        log_output = circuit(batch)                 # Compute the log output of the circuit\n",
    "        log_pf = pf_circuit()                       # Compute the log partition function of the circuit\n",
    "        lls = log_output - log_pf                   # Compute the log-likelihood\n",
    "        loss = -torch.mean(lls)   # The loss is the negative average log-likelihood\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        running_loss += loss.detach() * len(batch)\n",
    "        step_idx += 1\n",
    "        if step_idx % 100 == 0:\n",
    "            print(f\"Step {step_idx}: Average NLL: {running_loss / (100 * len(batch)):.3f}\")\n",
    "            running_loss = 0.0"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100: Average NLL: 1936.779\n",
      "Step 200: Average NLL: 977.104\n",
      "Step 300: Average NLL: 941.273\n",
      "Step 400: Average NLL: 928.190\n",
      "Step 500: Average NLL: 916.137\n",
      "Step 600: Average NLL: 898.607\n",
      "Step 700: Average NLL: 880.481\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "id": "50efae6b",
   "metadata": {},
   "source": [
    "We then evaluate our model on test data by computing the average log-likelihood and bits per dimension."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T09:32:57.292381Z",
     "start_time": "2024-07-29T09:32:56.231494Z"
    }
   },
   "cell_type": "code",
   "source": [
    "circuit.eval()\n",
    "pf_circuit.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_lls = 0.0\n",
    "    log_pf = pf_circuit()  # Compute the log partition function of the circuit (just once as we are evaluating)\n",
    "    for batch, _ in test_dataloader:\n",
    "        batch = batch.to(device).unsqueeze(dim=1)   # Add a channel dimension\n",
    "        log_output = circuit(batch)                 # Compute the log output of the circuit\n",
    "        lls = log_output - log_pf                   # Compute the log-likelihood\n",
    "        test_lls += lls.sum().item()\n",
    "    average_ll = test_lls / len(data_test)\n",
    "    bpd = -average_ll / (num_variables * np.log(2.0))\n",
    "    print(f\"Average test LL: {average_ll:.3f}\")\n",
    "    print(f\"Bits per dimension: {bpd}\")"
   ],
   "id": "fc335f725d9f18d4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average test LL: -871.229\n",
      "Bits per dimension: 1.6032109096272653\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Forward Sampling from the Circuit\n",
    "\n",
    "To visualise the generative capabilities of the circuit, we can sample from it by performing forward sampling and plot the results. Note that the sampling operation returns samples from the leaves *and* samples from the corresponding mixtures."
   ],
   "id": "9b11214b2c17f2e0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T09:32:57.648478Z",
     "start_time": "2024-07-29T09:32:57.293484Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import einops as E\n",
    "\n",
    "samples = circuit.sample_forward(5)\n",
    "leaf_samples = samples[0]\n",
    "mixtures_samples = samples[1]\n",
    "\n",
    "leaf_samples = leaf_samples[:, 0, :] # Remove the channel dimension\n",
    "samples = E.rearrange(samples, \"n (h w) -> n h w\", h=28, w=28)\n",
    "samples = samples.cpu().numpy()\n",
    "\n",
    "plt.figure(figsize=(5, 1))\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i + 1)\n",
    "    plt.imshow(samples[i], cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "plt.show(bbox_inches=\"tight\", pad_inches=0, transparent=True)"
   ],
   "id": "2bc2244ab3fc34ca",
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [22]\u001B[0m, in \u001B[0;36m<cell line: 7>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      4\u001B[0m leaf_samples \u001B[38;5;241m=\u001B[39m samples[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m      5\u001B[0m mixtures_samples \u001B[38;5;241m=\u001B[39m samples[\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m----> 7\u001B[0m leaf_samples \u001B[38;5;241m=\u001B[39m \u001B[43mleaf_samples\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m      8\u001B[0m samples \u001B[38;5;241m=\u001B[39m E\u001B[38;5;241m.\u001B[39mrearrange(samples, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mn (h w) -> n h w\u001B[39m\u001B[38;5;124m\"\u001B[39m, h\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m28\u001B[39m, w\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m28\u001B[39m)\n\u001B[1;32m      9\u001B[0m samples \u001B[38;5;241m=\u001B[39m samples\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mnumpy()\n",
      "\u001B[0;31mIndexError\u001B[0m: too many indices for tensor of dimension 3"
     ]
    }
   ],
   "execution_count": 22
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
