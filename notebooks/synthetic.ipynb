{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-02T10:24:42.118024Z",
     "start_time": "2024-09-02T10:24:42.052587Z"
    }
   },
   "source": [
    "import random\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T10:24:42.135635Z",
     "start_time": "2024-09-02T10:24:42.129776Z"
    }
   },
   "cell_type": "code",
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)"
   ],
   "id": "681277d408d33fae",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T10:24:42.193885Z",
     "start_time": "2024-09-02T10:24:42.179331Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from cirkit.utils.scope import Scope\n",
    "from cirkit.symbolic.parameters import LogSoftmaxParameter, ExpParameter, Parameter, TensorParameter, SoftmaxParameter\n",
    "from cirkit.symbolic.layers import CategoricalLayer, MixingLayer, HadamardLayer\n",
    "from cirkit.symbolic.initializers import NormalInitializer\n",
    "from cirkit.symbolic.circuit import Circuit"
   ],
   "id": "eea8e699b52e454f",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T10:24:42.227040Z",
     "start_time": "2024-09-02T10:24:42.223548Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def categorical_layer_factory(\n",
    "    scope: Scope,\n",
    "    num_units: int,\n",
    "    num_channels: int,\n",
    "    num_categories: int\n",
    ") -> CategoricalLayer:\n",
    "    return CategoricalLayer(\n",
    "        scope, num_units, num_channels, num_categories=num_categories,\n",
    "        logits_factory=lambda shape: Parameter.from_unary(\n",
    "            LogSoftmaxParameter(shape),\n",
    "            TensorParameter(*shape, initializer=NormalInitializer(0.0, 1e-2))\n",
    "        )\n",
    "    )\n",
    "\n",
    "def mixing_layer_factory(\n",
    "    scope: Scope, num_units: int, arity: int\n",
    ") -> MixingLayer:\n",
    "    return MixingLayer(\n",
    "        scope, num_units, arity,\n",
    "        weight_factory=lambda shape: Parameter.from_unary(\n",
    "            SoftmaxParameter(shape),\n",
    "            TensorParameter(*shape, initializer=NormalInitializer(0.0, 1e-1))\n",
    "        )\n",
    "    )\n",
    "\n",
    "def hadamard_layer_factory(scope: Scope, num_input_units: int, arity: int) -> HadamardLayer:\n",
    "    return HadamardLayer(scope, num_input_units, arity)"
   ],
   "id": "49554fa60f8a0b24",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T10:24:42.277887Z",
     "start_time": "2024-09-02T10:24:42.272043Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n_variables = 13\n",
    "n_channels = 3\n",
    "n_categories = 17\n",
    "n_components = 11\n",
    "\n",
    "layers = [\n",
    "    categorical_layer_factory(range(n_variables // 2), 1, n_channels, n_categories)\n",
    "    for _ in range(n_components)\n",
    "]\n",
    "layers.extend(\n",
    "    [\n",
    "        categorical_layer_factory(range(n_variables // 2, n_variables), 1, n_channels, n_categories)\n",
    "        for _ in range(n_components)\n",
    "    ]\n",
    ")\n",
    "layers.append(mixing_layer_factory(range(n_variables // 2), 1, n_components))\n",
    "layers.append(mixing_layer_factory(range(n_variables // 2, n_variables), 1, n_components))\n",
    "layers.append(hadamard_layer_factory(range(n_variables), 2, n_components))\n",
    "\n",
    "in_layers = dict()\n",
    "in_layers[layers[-3]] = layers[:n_components]\n",
    "in_layers[layers[-2]] = layers[n_components : 2 * n_components]\n",
    "in_layers[layers[-1]] = layers[-3:-1]\n",
    "\n",
    "out_layers = dict()\n",
    "for i in range(n_components):\n",
    "    out_layers[layers[i]] = [layers[-3]]\n",
    "    out_layers[layers[i + n_components]] = [layers[-2]]\n",
    "out_layers[layers[-3]] = [layers[-1]]\n",
    "out_layers[layers[-2]] = [layers[-1]]\n",
    "\n",
    "circuit = Circuit(\n",
    "    scope=range(n_variables),\n",
    "    num_channels=n_channels,\n",
    "    layers=layers,\n",
    "    in_layers=in_layers,\n",
    "    outputs=out_layers,\n",
    "    topologically_ordered=True\n",
    ")"
   ],
   "id": "a7795e2565d01108",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T10:24:43.129714Z",
     "start_time": "2024-09-02T10:24:42.322280Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "device = torch.device('cuda')  # The device to use\n",
    "torch.manual_seed(42)\n",
    "if 'cuda' in device.type:\n",
    "    torch.cuda.manual_seed(42)\n",
    "    \n",
    "from cirkit.pipeline import PipelineContext"
   ],
   "id": "c8a1a2f08dba7835",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Start testing with unfolded circuits, implementation will be more intuitive and has to be there anyway.",
   "id": "1ca4070a63df9622"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T10:24:43.145034Z",
     "start_time": "2024-09-02T10:24:43.136818Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ctx = PipelineContext(\n",
    "    backend='torch',\n",
    "    fold=True,\n",
    "    semiring='lse-sum',\n",
    "    optimize=False,\n",
    ")\n",
    "circuit = ctx.compile(circuit)"
   ],
   "id": "b756ba6757b8a774",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T10:24:43.185351Z",
     "start_time": "2024-09-02T10:24:43.182227Z"
    }
   },
   "cell_type": "code",
   "source": "print(len(list(circuit.layers)))",
   "id": "4a13b3b2f4c998a4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T10:24:43.234301Z",
     "start_time": "2024-09-02T10:24:43.231361Z"
    }
   },
   "cell_type": "code",
   "source": "print(circuit)",
   "id": "38a5c56f0849678f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TorchCircuit(\n",
      "  (_nodes): ModuleList(\n",
      "    (0-1): 2 x TorchCategoricalLayer(\n",
      "      (logits): TorchParameter(\n",
      "        (_nodes): ModuleList(\n",
      "          (0): TorchTensorParameter()\n",
      "          (1): TorchLogSoftmaxParameter()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): TorchMixingLayer(\n",
      "      (weight): TorchParameter(\n",
      "        (_nodes): ModuleList(\n",
      "          (0): TorchTensorParameter()\n",
      "          (1): TorchSoftmaxParameter()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): TorchHadamardLayer()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T10:24:43.671611Z",
     "start_time": "2024-09-02T10:24:43.282303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "samples = circuit.sample_forward(100)\n",
    "\n",
    "print(samples.shape)\n",
    "\n",
    "log_samples = circuit(samples)\n",
    "\n",
    "print(log_samples.shape)"
   ],
   "id": "ddabc55b58056509",
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Multivariate Categorical sampling is not implemented yet!",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNotImplementedError\u001B[0m                       Traceback (most recent call last)",
      "Input \u001B[0;32mIn [10]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m samples \u001B[38;5;241m=\u001B[39m \u001B[43mcircuit\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msample_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(samples\u001B[38;5;241m.\u001B[39mshape)\n\u001B[1;32m      5\u001B[0m log_samples \u001B[38;5;241m=\u001B[39m circuit(samples)\n",
      "File \u001B[0;32m~/Documents/Code/cirkit/cirkit/backend/torch/circuits.py:216\u001B[0m, in \u001B[0;36mTorchCircuit.sample_forward\u001B[0;34m(self, num_samples)\u001B[0m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msample_forward\u001B[39m(\u001B[38;5;28mself\u001B[39m, num_samples: \u001B[38;5;28mint\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[Tensor, Tensor]:\n\u001B[0;32m--> 216\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sample_layers_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnum_samples\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Code/cirkit/cirkit/backend/torch/circuits.py:178\u001B[0m, in \u001B[0;36mAbstractTorchCircuit._sample_layers_forward\u001B[0;34m(self, num_samples)\u001B[0m\n\u001B[1;32m    176\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_sample_layers_forward\u001B[39m(\u001B[38;5;28mself\u001B[39m, num_samples: \u001B[38;5;28mint\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[Tensor, Tensor]:\n\u001B[1;32m    177\u001B[0m     \u001B[38;5;66;03m# Sample layers\u001B[39;00m\n\u001B[0;32m--> 178\u001B[0m     y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sample_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnum_samples\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    179\u001B[0m     samples \u001B[38;5;241m=\u001B[39m y[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m, :, :]  \u001B[38;5;66;03m# (C, N, D)\u001B[39;00m\n\u001B[1;32m    180\u001B[0m     samples \u001B[38;5;241m=\u001B[39m E\u001B[38;5;241m.\u001B[39mrearrange(samples, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mc n d -> n c d\u001B[39m\u001B[38;5;124m\"\u001B[39m)  \u001B[38;5;66;03m# (N, C, D\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/Code/cirkit/cirkit/backend/torch/graph/modules.py:174\u001B[0m, in \u001B[0;36mTorchDiAcyclicGraph._sample_forward\u001B[0;34m(self, num_samples)\u001B[0m\n\u001B[1;32m    171\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m output, mixture_outputs\n\u001B[1;32m    172\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m inputs \u001B[38;5;241m==\u001B[39m ():\n\u001B[1;32m    173\u001B[0m     \u001B[38;5;66;03m# input nodes take no inputs for sampling\u001B[39;00m\n\u001B[0;32m--> 174\u001B[0m     y \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msample_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnum_samples\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    175\u001B[0m     y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pad_samples(y, module\u001B[38;5;241m.\u001B[39mscope)\n\u001B[1;32m    176\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    177\u001B[0m     \u001B[38;5;66;03m# inner nodes take inputs for sampling\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/Code/cirkit/cirkit/backend/torch/layers/input/ef.py:174\u001B[0m, in \u001B[0;36mTorchCategoricalLayer.sample_forward\u001B[0;34m(self, num_samples, x)\u001B[0m\n\u001B[1;32m    172\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msample_forward\u001B[39m(\u001B[38;5;28mself\u001B[39m, num_samples: \u001B[38;5;28mint\u001B[39m, x: Optional[Tensor] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m    173\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscope) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m--> 174\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMultivariate Categorical sampling is not implemented yet!\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    175\u001B[0m     logits \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mlog(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprobs()) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlogits \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlogits()\n\u001B[1;32m    176\u001B[0m     distribution \u001B[38;5;241m=\u001B[39m distributions\u001B[38;5;241m.\u001B[39mCategorical(logits\u001B[38;5;241m=\u001B[39mlogits)\n",
      "\u001B[0;31mNotImplementedError\u001B[0m: Multivariate Categorical sampling is not implemented yet!"
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
