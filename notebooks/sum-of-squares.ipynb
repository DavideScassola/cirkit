{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7369e801-4318-4dee-b77c-5564cc99a6c4",
   "metadata": {},
   "source": [
    "# Sum of Squares Circuits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06696904-6240-4406-862e-eadad41e476b",
   "metadata": {},
   "source": [
    "## Complex Squared Circuits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08609db7-439a-48fa-9969-a4b2813c35bc",
   "metadata": {},
   "source": [
    "TODO: write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "667f60ee-5f58-4146-93cf-7675d222bd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cirkit.templates import circuit_templates\n",
    "from cirkit.symbolic.circuit import Circuit\n",
    "\n",
    "def build_symbolic_complex_circuit(region_graph: str) -> Circuit:\n",
    "    return circuit_templates.image_data(\n",
    "        (1, 28, 28),                 # The shape of MNIST image, i.e., (num_channels, image_height, image_width)\n",
    "        region_graph=region_graph,\n",
    "        # ----------- Input layers hyperparameters ----------- #\n",
    "        input_layer='embedding',     # Use Embedding maps for the pixel values (0-255) as input layers\n",
    "        num_input_units=32,          # Each input layer consists of 64 input units that output Embedding entries\n",
    "        input_params={               # Set how to parameterize the input layers parameters\n",
    "            # In this case we parameterize the 'weight' parameter of Embedding layers,\n",
    "            # by choosing them to be complex-valued whose real and imaginary part are sampled uniformly in [0, 1)\n",
    "            'weight': circuit_templates.Parameterization(dtype='complex', initialization='uniform'),\n",
    "        },\n",
    "        # -------- Sum-product layers hyperparameters -------- #\n",
    "        sum_product_layer='cp-t',    # Use CP-T sum-product layers, i.e., alternate hadamard product layers and dense layers\n",
    "        num_sum_units=32,            # Each dense sum layer consists of 64 sum units\n",
    "        # Set how to parameterize the sum layers parameters\n",
    "        # We paramterize them to be complex-valued whose real and imaginary part are sampled uniformly in [0, 1)\n",
    "        sum_weight_param = circuit_templates.Parameterization(dtype='complex', initialization='uniform')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ce05897-5107-4c6a-88d9-11146ee53a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbolic_circuit = build_symbolic_complex_circuit('quad-tree-4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a296e080-6ec8-4fcc-99c6-3d9662813d4e",
   "metadata": {},
   "source": [
    "TODO: write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3222cff6-4423-4c30-8964-6685be991798",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cirkit.symbolic.functional as SF\n",
    "\n",
    "symbolic_circuit_partition_func = SF.integrate(\n",
    "    SF.multiply(symbolic_circuit, SF.conjugate(symbolic_circuit))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629a58ed-bcab-473f-9d14-3d7768103af3",
   "metadata": {},
   "source": [
    "TODO: write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f46dc6a2-bf46-49a8-9dc9-d9b3c12411cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cirkit.pipeline import PipelineContext, compile\n",
    "\n",
    "# Instantiate the pipeline context\n",
    "ctx = PipelineContext(backend='torch', semiring='complex-lse-sum', fold=True, optimize=True)\n",
    "\n",
    "with ctx:\n",
    "    circuit = compile(symbolic_circuit)\n",
    "    circuit_partition_func = compile(symbolic_circuit_partition_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2926a18a-ce50-4787-859f-22d2f4398fa5",
   "metadata": {},
   "source": [
    "TODO: write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0dfff6-a526-4a80-a5b8-6f89e911deee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "# Load the MNIST data set and data loaders\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # Flatten the images and set pixel values in the [0-255] range\n",
    "    transforms.Lambda(lambda x: (255 * x.view(-1)).long())\n",
    "])\n",
    "data_train = datasets.MNIST('datasets', train=True, download=True, transform=transform)\n",
    "data_test = datasets.MNIST('datasets', train=False, download=True, transform=transform)\n",
    "\n",
    "# Instantiate the training and testing data loaders\n",
    "train_dataloader = DataLoader(data_train, shuffle=True, batch_size=256)\n",
    "test_dataloader = DataLoader(data_test, shuffle=False, batch_size=256)\n",
    "\n",
    "# Initialize a torch optimizer of your choice,\n",
    "#  e.g., Adam, by passing the parameters of the circuit\n",
    "optimizer = optim.Adam(circuit.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24176b6e-a495-4ce3-b627-d893507e2c35",
   "metadata": {},
   "source": [
    "TODO: write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02c0673-a16f-4d7f-b7a0-7f8a6507fac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "step_idx = 0\n",
    "running_loss = 0.0\n",
    "\n",
    "# Move the circuit to chosen device\n",
    "circuit = circuit.to(device)\n",
    "\n",
    "for epoch_idx in range(num_epochs):\n",
    "    for i, (batch, _) in enumerate(train_dataloader):\n",
    "        # The circuit expects an input of shape (batch_dim, num_channels, num_variables),\n",
    "        # so we unsqueeze a dimension for the channel.\n",
    "        batch = batch.to(device).unsqueeze(dim=1)\n",
    "\n",
    "        # Compute the logarithm of the squared scores of the batch, by evaluating the circuit\n",
    "        log_scores = circuit(batch)\n",
    "        log_squared_scores = 2.0 * log_scores.real\n",
    "        \n",
    "        # Compute the log-partition function\n",
    "        log_partition_func = circuit_partition_func().real\n",
    "\n",
    "        # Compute the log-likelihoods\n",
    "        log_likelihoods = log_squared_scores - log_partition_func\n",
    "\n",
    "        # We take the negated average log-likelihood as loss\n",
    "        loss = -torch.mean(log_likelihoods)\n",
    "        loss.backward()\n",
    "        # Update the parameters of the circuits, as any other model in PyTorch\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        running_loss += loss.detach() * len(batch)\n",
    "        step_idx += 1\n",
    "        if step_idx % 100 == 0:\n",
    "            print(f\"Step {step_idx}: Average NLL: {running_loss / (100 * len(batch)):.3f}\")\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916638d9-6176-487d-8ac9-b048c81680a9",
   "metadata": {},
   "source": [
    "TODO: write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5148696f-7721-4cae-8027-7faa0dc33515",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    test_lls = 0.0\n",
    "\n",
    "    for batch, _ in test_dataloader:\n",
    "        # The circuit expects an input of shape (batch_dim, num_channels, num_variables),\n",
    "        # so we unsqueeze a dimension for the channel.\n",
    "        batch = batch.to(device).unsqueeze(dim=1)\n",
    "\n",
    "        # Compute the log-likelihoods of the batch\n",
    "        log_likelihoods = circuit(batch)\n",
    "\n",
    "        # Accumulate the log-likelihoods\n",
    "        test_lls += log_likelihoods.sum().item()\n",
    "\n",
    "    # Compute average test log-likelihood and bits per dimension\n",
    "    average_ll = test_lls / len(data_test)\n",
    "    bpd = -average_ll / (28 * 28 * np.log(2.0))\n",
    "    print(f\"Average test LL: {average_ll:.3f}\")\n",
    "    print(f\"Bits per dimension: {bpd:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d299e3-70fb-47d4-a54d-aa8e082a689a",
   "metadata": {},
   "source": [
    "TODO: write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fbb0e3-5cef-4277-ab05-b4789d3577a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
