import functools
import itertools
import torch
import einops as E

from abc import ABC
from torch import Tensor
from typing import List, Tuple

from cirkit.backend.torch.circuits import TorchCircuit
from cirkit.backend.torch.layers import TorchInputLayer, TorchLayer
from cirkit.utils.scope import Scope


class Query(ABC):
    """An object used to run queries of circuits compiled using the torch backend."""

    def __init__(self) -> None:
        ...


class SamplingQuery(Query):
    """The sampling query object."""

    def __init__(self, circuit: TorchCircuit) -> None:
        """
        Initialize a sampling query object.

        Args:
            circuit: The circuit to sample from.

        Raises:
            ValueError: If the circuit to sample from is not normalised.
        """
        dummy = False
        if dummy:
            raise ValueError(
                f"The circuit to sample must be normalised, but there are unnormalised layers"
            )
        super().__init__()
        self._circuit = circuit

    def __call__(self, num_samples: int) -> Tuple[Tensor, List[Tensor]]:
        """
        Return a set of samples from the circuit of the desired size.

        @param num_samples: The number of samples to return.

        @return: A tuple t with t[0] the samples generated by the computational graph and t[1] the list of samples of the mixture branches
        @return shape: (folds, channels, cardinality, samples, circuit_scope)
        """

        module_outputs: List[Tensor] = []
        mixture_outputs: List[Tensor] = []
        inputs_iterator = self._circuit._address_book.lookup(module_outputs)
        for module, inputs in itertools.zip_longest(self._circuit.topological_ordering(), inputs_iterator):
            if module is None:
                (output,) = inputs
                output = output[0, 0, :, :]  # (C, N, D)
                output = E.rearrange(output, "c n d -> n c d")  # (N, C, D
                return output, mixture_outputs
            elif inputs == ():
                # input nodes take no inputs for sampling
                y = module.sample(num_samples)
                y = self._pad_samples(y, module.scope)
            else:
                # inner nodes take inputs for sampling
                y = module.sample(num_samples, *inputs)
            if type(y) is tuple:
                module_outputs.append(y[0])
                mixture_outputs.append(y[1])
            else:
                module_outputs.append(y)


    def _pad_samples(self, y: Tensor, scope: Scope) -> Tensor:
        """
        Pads univariate samples to the size of the scope of the circuit (output dimension) according to scope for
        compatibility in downstream inner nodes. Currently only supports unfolded or folded where the leaf nodes
        are all folded into one fold.

        @param y: The samples to pad
        @shape y: (folds, channels, cardinality, samples)
        @param scope: The scope of the leaf node module outputting the samples

        @return: The padded samples
        @return shape: (folds, channels, cardinality, samples, circuit_scope)
        """
        # Ideally, here we need to pad with the zero element of the semiring, I think.
        # pad = torch.ones_like(y[..., 0]) * self.semiring.zero

        pad = torch.zeros_like(y)

        padded_samples = []
        if y.shape[0] == 1:
            running_scope = 0
            for variable in self._circuit.scope:
                if variable in scope:
                    padded_samples.append(y)
                    running_scope += 1
                else:
                    padded_samples.append(pad)
            padded_samples = torch.stack(padded_samples, dim=-1)
        elif len(self._circuit.scope) == y.shape[0]:
            c = y.shape[1]
            k = y.shape[2]

            padded_samples = E.repeat(y, "f c k n -> (c k n) f d", d=len(self._circuit.scope))
            indicator = torch.eye(
                len(self._circuit.scope), dtype=padded_samples.dtype, device=padded_samples.device
            )
            indicator = indicator.unsqueeze(0)

            padded_samples = padded_samples * indicator
            padded_samples = E.rearrange(padded_samples, "(c k n) f d -> f c k n d", c=c, k=k)
        else:
            # Arbitrary padding would require more information on the scope,
            # i.e. having a folded scope, otherwise not enough information.
            raise NotImplementedError("Padding for arbitrary folds not supported!")
        return padded_samples